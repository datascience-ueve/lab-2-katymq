{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2. PARTIE 1. scikit-learn + Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module de Machine Learning en Python : scitkit-learn (sklearn)\n",
    "http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan :\n",
    "\n",
    "   [- Iris dataset](#1)\n",
    "   \n",
    "   [- Naive Bayes](#2)\n",
    "   \n",
    "   [- Mon Naive Bayes](#3)\n",
    "   \n",
    "   [- Tests](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scipy-lectures.org/advanced/scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher le dataset **iris** dans le module sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Analyser les r√©sultats des commandes suivantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "        [ 4.9,  3. ,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.3,  0.2],\n",
       "        [ 4.6,  3.1,  1.5,  0.2],\n",
       "        [ 5. ,  3.6,  1.4,  0.2],\n",
       "        [ 5.4,  3.9,  1.7,  0.4],\n",
       "        [ 4.6,  3.4,  1.4,  0.3],\n",
       "        [ 5. ,  3.4,  1.5,  0.2],\n",
       "        [ 4.4,  2.9,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5.4,  3.7,  1.5,  0.2],\n",
       "        [ 4.8,  3.4,  1.6,  0.2],\n",
       "        [ 4.8,  3. ,  1.4,  0.1],\n",
       "        [ 4.3,  3. ,  1.1,  0.1],\n",
       "        [ 5.8,  4. ,  1.2,  0.2],\n",
       "        [ 5.7,  4.4,  1.5,  0.4],\n",
       "        [ 5.4,  3.9,  1.3,  0.4],\n",
       "        [ 5.1,  3.5,  1.4,  0.3],\n",
       "        [ 5.7,  3.8,  1.7,  0.3],\n",
       "        [ 5.1,  3.8,  1.5,  0.3],\n",
       "        [ 5.4,  3.4,  1.7,  0.2],\n",
       "        [ 5.1,  3.7,  1.5,  0.4],\n",
       "        [ 4.6,  3.6,  1. ,  0.2],\n",
       "        [ 5.1,  3.3,  1.7,  0.5],\n",
       "        [ 4.8,  3.4,  1.9,  0.2],\n",
       "        [ 5. ,  3. ,  1.6,  0.2],\n",
       "        [ 5. ,  3.4,  1.6,  0.4],\n",
       "        [ 5.2,  3.5,  1.5,  0.2],\n",
       "        [ 5.2,  3.4,  1.4,  0.2],\n",
       "        [ 4.7,  3.2,  1.6,  0.2],\n",
       "        [ 4.8,  3.1,  1.6,  0.2],\n",
       "        [ 5.4,  3.4,  1.5,  0.4],\n",
       "        [ 5.2,  4.1,  1.5,  0.1],\n",
       "        [ 5.5,  4.2,  1.4,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 5. ,  3.2,  1.2,  0.2],\n",
       "        [ 5.5,  3.5,  1.3,  0.2],\n",
       "        [ 4.9,  3.1,  1.5,  0.1],\n",
       "        [ 4.4,  3. ,  1.3,  0.2],\n",
       "        [ 5.1,  3.4,  1.5,  0.2],\n",
       "        [ 5. ,  3.5,  1.3,  0.3],\n",
       "        [ 4.5,  2.3,  1.3,  0.3],\n",
       "        [ 4.4,  3.2,  1.3,  0.2],\n",
       "        [ 5. ,  3.5,  1.6,  0.6],\n",
       "        [ 5.1,  3.8,  1.9,  0.4],\n",
       "        [ 4.8,  3. ,  1.4,  0.3],\n",
       "        [ 5.1,  3.8,  1.6,  0.2],\n",
       "        [ 4.6,  3.2,  1.4,  0.2],\n",
       "        [ 5.3,  3.7,  1.5,  0.2],\n",
       "        [ 5. ,  3.3,  1.4,  0.2],\n",
       "        [ 7. ,  3.2,  4.7,  1.4],\n",
       "        [ 6.4,  3.2,  4.5,  1.5],\n",
       "        [ 6.9,  3.1,  4.9,  1.5],\n",
       "        [ 5.5,  2.3,  4. ,  1.3],\n",
       "        [ 6.5,  2.8,  4.6,  1.5],\n",
       "        [ 5.7,  2.8,  4.5,  1.3],\n",
       "        [ 6.3,  3.3,  4.7,  1.6],\n",
       "        [ 4.9,  2.4,  3.3,  1. ],\n",
       "        [ 6.6,  2.9,  4.6,  1.3],\n",
       "        [ 5.2,  2.7,  3.9,  1.4],\n",
       "        [ 5. ,  2. ,  3.5,  1. ],\n",
       "        [ 5.9,  3. ,  4.2,  1.5],\n",
       "        [ 6. ,  2.2,  4. ,  1. ],\n",
       "        [ 6.1,  2.9,  4.7,  1.4],\n",
       "        [ 5.6,  2.9,  3.6,  1.3],\n",
       "        [ 6.7,  3.1,  4.4,  1.4],\n",
       "        [ 5.6,  3. ,  4.5,  1.5],\n",
       "        [ 5.8,  2.7,  4.1,  1. ],\n",
       "        [ 6.2,  2.2,  4.5,  1.5],\n",
       "        [ 5.6,  2.5,  3.9,  1.1],\n",
       "        [ 5.9,  3.2,  4.8,  1.8],\n",
       "        [ 6.1,  2.8,  4. ,  1.3],\n",
       "        [ 6.3,  2.5,  4.9,  1.5],\n",
       "        [ 6.1,  2.8,  4.7,  1.2],\n",
       "        [ 6.4,  2.9,  4.3,  1.3],\n",
       "        [ 6.6,  3. ,  4.4,  1.4],\n",
       "        [ 6.8,  2.8,  4.8,  1.4],\n",
       "        [ 6.7,  3. ,  5. ,  1.7],\n",
       "        [ 6. ,  2.9,  4.5,  1.5],\n",
       "        [ 5.7,  2.6,  3.5,  1. ],\n",
       "        [ 5.5,  2.4,  3.8,  1.1],\n",
       "        [ 5.5,  2.4,  3.7,  1. ],\n",
       "        [ 5.8,  2.7,  3.9,  1.2],\n",
       "        [ 6. ,  2.7,  5.1,  1.6],\n",
       "        [ 5.4,  3. ,  4.5,  1.5],\n",
       "        [ 6. ,  3.4,  4.5,  1.6],\n",
       "        [ 6.7,  3.1,  4.7,  1.5],\n",
       "        [ 6.3,  2.3,  4.4,  1.3],\n",
       "        [ 5.6,  3. ,  4.1,  1.3],\n",
       "        [ 5.5,  2.5,  4. ,  1.3],\n",
       "        [ 5.5,  2.6,  4.4,  1.2],\n",
       "        [ 6.1,  3. ,  4.6,  1.4],\n",
       "        [ 5.8,  2.6,  4. ,  1.2],\n",
       "        [ 5. ,  2.3,  3.3,  1. ],\n",
       "        [ 5.6,  2.7,  4.2,  1.3],\n",
       "        [ 5.7,  3. ,  4.2,  1.2],\n",
       "        [ 5.7,  2.9,  4.2,  1.3],\n",
       "        [ 6.2,  2.9,  4.3,  1.3],\n",
       "        [ 5.1,  2.5,  3. ,  1.1],\n",
       "        [ 5.7,  2.8,  4.1,  1.3],\n",
       "        [ 6.3,  3.3,  6. ,  2.5],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 7.1,  3. ,  5.9,  2.1],\n",
       "        [ 6.3,  2.9,  5.6,  1.8],\n",
       "        [ 6.5,  3. ,  5.8,  2.2],\n",
       "        [ 7.6,  3. ,  6.6,  2.1],\n",
       "        [ 4.9,  2.5,  4.5,  1.7],\n",
       "        [ 7.3,  2.9,  6.3,  1.8],\n",
       "        [ 6.7,  2.5,  5.8,  1.8],\n",
       "        [ 7.2,  3.6,  6.1,  2.5],\n",
       "        [ 6.5,  3.2,  5.1,  2. ],\n",
       "        [ 6.4,  2.7,  5.3,  1.9],\n",
       "        [ 6.8,  3. ,  5.5,  2.1],\n",
       "        [ 5.7,  2.5,  5. ,  2. ],\n",
       "        [ 5.8,  2.8,  5.1,  2.4],\n",
       "        [ 6.4,  3.2,  5.3,  2.3],\n",
       "        [ 6.5,  3. ,  5.5,  1.8],\n",
       "        [ 7.7,  3.8,  6.7,  2.2],\n",
       "        [ 7.7,  2.6,  6.9,  2.3],\n",
       "        [ 6. ,  2.2,  5. ,  1.5],\n",
       "        [ 6.9,  3.2,  5.7,  2.3],\n",
       "        [ 5.6,  2.8,  4.9,  2. ],\n",
       "        [ 7.7,  2.8,  6.7,  2. ],\n",
       "        [ 6.3,  2.7,  4.9,  1.8],\n",
       "        [ 6.7,  3.3,  5.7,  2.1],\n",
       "        [ 7.2,  3.2,  6. ,  1.8],\n",
       "        [ 6.2,  2.8,  4.8,  1.8],\n",
       "        [ 6.1,  3. ,  4.9,  1.8],\n",
       "        [ 6.4,  2.8,  5.6,  2.1],\n",
       "        [ 7.2,  3. ,  5.8,  1.6],\n",
       "        [ 7.4,  2.8,  6.1,  1.9],\n",
       "        [ 7.9,  3.8,  6.4,  2. ],\n",
       "        [ 6.4,  2.8,  5.6,  2.2],\n",
       "        [ 6.3,  2.8,  5.1,  1.5],\n",
       "        [ 6.1,  2.6,  5.6,  1.4],\n",
       "        [ 7.7,  3. ,  6.1,  2.3],\n",
       "        [ 6.3,  3.4,  5.6,  2.4],\n",
       "        [ 6.4,  3.1,  5.5,  1.8],\n",
       "        [ 6. ,  3. ,  4.8,  1.8],\n",
       "        [ 6.9,  3.1,  5.4,  2.1],\n",
       "        [ 6.7,  3.1,  5.6,  2.4],\n",
       "        [ 6.9,  3.1,  5.1,  2.3],\n",
       "        [ 5.8,  2.7,  5.1,  1.9],\n",
       "        [ 6.8,  3.2,  5.9,  2.3],\n",
       "        [ 6.7,  3.3,  5.7,  2.5],\n",
       "        [ 6.7,  3. ,  5.2,  2.3],\n",
       "        [ 6.3,  2.5,  5. ,  1.9],\n",
       "        [ 6.5,  3. ,  5.2,  2. ],\n",
       "        [ 6.2,  3.4,  5.4,  2.3],\n",
       "        [ 5.9,  3. ,  5.1,  1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'],\n",
       "       dtype='<U10')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class of each observation is stored in the .target attribute of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GaussianNB in module sklearn.naive_bayes:\n",
      "\n",
      "class GaussianNB(BaseNB)\n",
      " |  Gaussian Naive Bayes (GaussianNB)\n",
      " |  \n",
      " |  Can perform online updates to model parameters via `partial_fit` method.\n",
      " |  For details on algorithm used to update feature means and variance online,\n",
      " |  see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
      " |  \n",
      " |      http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  priors : array-like, shape (n_classes,)\n",
      " |      Prior probabilities of the classes. If specified the priors are not\n",
      " |      adjusted according to the data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_prior_ : array, shape (n_classes,)\n",
      " |      probability of each class.\n",
      " |  \n",
      " |  class_count_ : array, shape (n_classes,)\n",
      " |      number of training samples observed in each class.\n",
      " |  \n",
      " |  theta_ : array, shape (n_classes, n_features)\n",
      " |      mean of each feature per class\n",
      " |  \n",
      " |  sigma_ : array, shape (n_classes, n_features)\n",
      " |      variance of each feature per class\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> from sklearn.naive_bayes import GaussianNB\n",
      " |  >>> clf = GaussianNB()\n",
      " |  >>> clf.fit(X, Y)\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  >>> clf_pf = GaussianNB()\n",
      " |  >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf_pf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GaussianNB\n",
      " |      BaseNB\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, priors=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Gaussian Naive Bayes according to X, y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Incremental fit on a batch of samples.\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different chunks of a dataset so as to implement out-of-core\n",
      " |      or online learning.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to fit in\n",
      " |      memory at once.\n",
      " |      \n",
      " |      This method has some performance and numerical stability overhead,\n",
      " |      hence it is better to call partial_fit on chunks of data that are\n",
      " |      as large as possible (as long as fitting in the memory budget) to\n",
      " |      hide the overhead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      classes : array-like, shape (n_classes,), optional (default=None)\n",
      " |          List of all the classes that can possibly appear in the y vector.\n",
      " |      \n",
      " |          Must be provided at the first call to partial_fit, can be omitted\n",
      " |          in subsequent calls.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseNB:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted target values for X\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return log-probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module sklearn.naive_bayes:\n",
      "\n",
      "fit(X, y, sample_weight=None) method of sklearn.naive_bayes.GaussianNB instance\n",
      "    Fit Gaussian Naive Bayes according to X, y\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape (n_samples, n_features)\n",
      "        Training vectors, where n_samples is the number of samples\n",
      "        and n_features is the number of features.\n",
      "    \n",
      "    y : array-like, shape (n_samples,)\n",
      "        Target values.\n",
      "    \n",
      "    sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      "        Weights applied to individual samples (1. for unweighted).\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "help(gnb.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On donne ici un exemple d'utilisation du Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a8957de8744b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m print(\"Number of mislabeled points out of a total   points : %d\"\n\u001b[1;32m----> 3\u001b[1;33m        % (iris.data.shape[0],(iris.target != y_pred).sum()))\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "print(\"Number of mislabeled points out of a total   points : %d\"\n",
    "       % (iris.data.shape[0],(iris.target != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c0ab2f85723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'iris' is not defined"
     ]
    }
   ],
   "source": [
    "(iris.target != y_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On s√©pare en 2 parties √©gales le dataset avec tirage al√©atoire sans remise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 95,  26, 139, 122,  41,  57,  77,  70, 111,  88,  58, 128, 143,\n",
       "       135, 105,  72, 123,  65, 118,  87,  67, 104,  15,  42,  49,  56,\n",
       "       114, 103, 138,   5,  45,  35,  18, 124,  43,  13, 140,  82, 149,\n",
       "         3,  75,  29,  16,  12, 137,  11, 126,  97,   8,  94, 125, 142,\n",
       "        99,  47, 106, 109,  39,  71,   1,  93,  80, 132,   4,  96,  53,\n",
       "        60, 107,  33, 116,  54,   7,  52,  31,  19,  63])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.random.choice(range(150), 75, replace=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   6,   9,  10,  14,  17,  20,  21,  22,  23,  24,  25,\n",
       "        27,  28,  30,  32,  34,  36,  37,  38,  40,  44,  46,  48,  50,\n",
       "        51,  55,  59,  61,  62,  64,  66,  68,  69,  73,  74,  76,  78,\n",
       "        79,  81,  83,  84,  85,  86,  89,  90,  91,  92,  98, 100, 101,\n",
       "       102, 108, 110, 112, 113, 115, 117, 119, 120, 121, 127, 129, 130,\n",
       "       131, 133, 134, 136, 141, 144, 145, 146, 147, 148])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.delete(range(150), train)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on regarde le r√©sutat sur la pr√©diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "100*(iris.target[test,] != y_pred).sum()/len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Construire une fonction NB de param√®tre A, B et nb qui r√©p√®te nb tirages al√©atoires avec i donn√©es pour la partie apprentissage et 150-i pour le test avec i allant de A √† B. La fonction renvoie une liste de taille B-A+1 avec le pourcentage de pr√©diction exacte sur les donn√©es de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86,  99,  52,  65, 143])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(150), 5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48.648648648648646,\n",
       " 47.61904761904763,\n",
       " 54.337899543378995,\n",
       " 46.20689655172415,\n",
       " 51.15740740740741,\n",
       " 45.68764568764569,\n",
       " 41.07981220657277,\n",
       " 33.333333333333336,\n",
       " 22.14285714285714,\n",
       " 23.02158273381295,\n",
       " 6.763285024154588,\n",
       " 35.523114355231144,\n",
       " 9.068627450980392,\n",
       " 27.160493827160494,\n",
       " 8.457711442786069,\n",
       " 17.79448621553885,\n",
       " 5.808080808080809,\n",
       " 4.8346055979643765,\n",
       " 8.461538461538462,\n",
       " 13.953488372093025,\n",
       " 9.635416666666666,\n",
       " 9.186351706036746,\n",
       " 6.613756613756614,\n",
       " 6.933333333333333,\n",
       " 5.645161290322581,\n",
       " 5.420054200542005,\n",
       " 7.923497267759562,\n",
       " 6.06060606060606,\n",
       " 7.500000000000001]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NB(A,B,nb):\n",
    "    res = []\n",
    "    for i in range(A,B+1):\n",
    "        temp = 0\n",
    "        for j in range(nb):\n",
    "            train = np.random.choice(range(150), i, replace=False)\n",
    "            test = np.delete(range(150), train)\n",
    "            y_pred = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "            temp = temp + 100*(iris.target[test,] != y_pred).sum()/len(test)\n",
    "        res = res + [temp/nb]\n",
    "    return res\n",
    "NB(2,30,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Tracer sur un graphique le vecteur NB(A,B,10) avec A = 2 et B = 149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = 2\n",
    "B = 149\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.linspace(A,B,B-A+1), NB(A,B,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mon Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Si Bayes est si naif que √ßa, pourquoi pas le construire nous-m√™me ! En s'aidant du cours, construire la fonction MonNaiveBayes sur le mod√®le suivant"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 4)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-787ce101ae5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mid_y0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mid_y0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: len() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "data_train=iris.data[train,]\n",
    "print(data_train.shape)\n",
    "target_train=iris.target[train,]\n",
    "id_y0=np.where(target_train==0)\n",
    "id_y0\n",
    "np.sum(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[id_y0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6  ,  2.1  ,  3.   ,  2.275,  2.475,  2.85 ,  2.375,  2.4  ,\n",
       "        2.875,  2.675,  2.125,  2.35 ,  2.425,  2.75 ,  2.325,  2.5  ,\n",
       "        2.225,  2.35 ,  2.55 ,  2.375,  2.55 ,  2.825,  2.525,  2.675,\n",
       "        2.675])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data_train[id_y0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.74928557,  1.55563492,  2.13658606,  1.62999233,  1.82944664,\n",
       "        1.93196791,  1.69760861,  1.8493242 ,  2.05228531,  1.69908063,\n",
       "        1.63152536,  1.65604952,  1.68874954,  1.99812412,  1.75979402,\n",
       "        1.74642492,  1.57856739,  1.68151717,  1.86077941,  1.76405074,\n",
       "        1.86748494,  2.1194044 ,  1.82671153,  1.90443561,  1.88198698])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(data_train[id_y0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05333333333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[id_y0].shape[1]/data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[id_y0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    x: valeur √† laquelle sera √©valu√©e delta, np.array  size d\n",
    "    mu_hat: moyenne des features, np.array size d\n",
    "    sigma_hat: std des features, np.array size d\n",
    "    pi_hat: proportion parmi le train, np.float\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(x,mu_hat,sigma_hat,pi_hat):\n",
    "    d=x.shape[0]\n",
    "    log_density_features=-d * np.log(np.sqrt(2*np.pi)) -np.sum(np.log(sigma_hat))-np.sum((x-mu_hat)**2/(2*sigma_hat**2),axis=1)\n",
    "    log_proba= np.log(pi_hat)\n",
    "    return log_density_features+log_proba\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "x=np.array([1.2,2.1,-1.5,-1])\n",
    "print(x.shape[0])\n",
    "d=x.shape[0]\n",
    "mu_hat0=np.mean(data_train[id_y0,],axis=1)\n",
    "sigma_hat0=np.std(data_train[id_y0,],axis=1)\n",
    "pi_hat0=data_train[id_y0,].shape[1]/data_train.shape[0]\n",
    "\n",
    "\n",
    "id_y1=np.where(target_train==1)\n",
    "mu_hat1=np.mean(data_train[id_y1,],axis=1)\n",
    "sigma_hat1=np.std(data_train[id_y1,],axis=1)\n",
    "pi_hat1=data_train[id_y1,].shape[1]/data_train.shape[0]\n",
    "\n",
    "id_y2=np.where(target_train==2)\n",
    "mu_hat2=np.mean(data_train[id_y2,],axis=1)\n",
    "sigma_hat2=np.std(data_train[id_y2,],axis=1)\n",
    "pi_hat2=data_train[id_y2,].shape[1]/data_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-330.08352147982902"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta(x,mu_hat0,sigma_hat0,pi_hat0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-182.15158253229518"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta(x,mu_hat1,sigma_hat1,pi_hat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-190.40613176511656"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta(x,mu_hat2,sigma_hat2,pi_hat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 6.9,  3.1,  5.4,  2.1]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data_train[0:3,:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.964,  3.38 ,  1.448,  0.264]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 225.1168704 ,    1.30821049,  534.13536301])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((x-mu_hat0)**2/(2*sigma_hat0**2),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui cambia, trabajo con x una matriz, entonces aumento axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_values=np.unique(target_label)\n",
    "n,d=train_features.shape\n",
    "#mu_hat=np.zeros((target_values.shape[0],d))\n",
    "#sigma_hat=np.zeros((target_values.shape[0],d))\n",
    "#pi_hat=np.zeros((target_values.shape[0]))\n",
    "mu_hat=[]\n",
    "sigma_hat=[]\n",
    "pi_hat=[]\n",
    "\"\"\"\n",
    "for y in np.unique(target_train):\n",
    "    print(y)\n",
    "    id_y1=np.where(target_train==y)\n",
    "    mu_hat[k,:]=np.mean(data_train[id_y,],axis=1)\n",
    "    sigma_hat[k,:]=np.std(data_train[id_y,],axis=1)\n",
    "    pi_hat[k]=data_train[id_y1,].shape[1]/data_train.shape[0]\n",
    "    k+=1\n",
    "print(mu_hat)\n",
    "\"\"\"\n",
    "for y in np.unique(target_train):\n",
    "    print(y)\n",
    "    id_y1=np.where(target_train==y)\n",
    "    mu_hat.append=np.mean(data_train[id_y,],axis=1)\n",
    "    sigma_hat.append=np.std(data_train[id_y,],axis=1)\n",
    "    pi_hat.append=data_train[id_y1,].shape[1]/data_train.shape[0]\n",
    "print(mu_hat)\n",
    "\n",
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MonNaiveBayes(train_features, train_label,test_features):\n",
    "    target_values=np.unique(train_label)\n",
    "    n,d=train_features.shape\n",
    "    mu_hat=[]\n",
    "    sigma_hat=[]\n",
    "    pi_hat=[]\n",
    "    for y in np.unique(target_train):\n",
    "        print(y)\n",
    "        id_y1=np.where(target_train==y)\n",
    "        mu_hat.append=np.mean(data_train[id_y,],axis=1)\n",
    "        sigma_hat.append=np.std(data_train[id_y,],axis=1)\n",
    "        pi_hat.append=data_train[id_y1,].shape[1]/data_train.shape[0]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour les matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MonNaiveBayes(train_features, train_label,test_features):\n",
    "    target_values=np.unique(train_label)\n",
    "    n_train,d_train=train_features.shape\n",
    "    n_test,d_test=test_features.shape\n",
    "    mu_hat=[]\n",
    "    sigma_hat=[]\n",
    "    pi_hat=[]\n",
    "    for y in np.unique(target_train):\n",
    "        print(y)\n",
    "        id_y=np.where(target_train==y)\n",
    "        mu_hat.append(np.mean(train_features[id_y,],axis=1))\n",
    "        sigma_hat.append(np.std(train_features[id_y,],axis=1))\n",
    "        pi_hat.append(train_features[id_y1,].shape[1]/data_train.shape[0])\n",
    "    delta_hat_test=np.zeros((n_test,target_values.shape[0]))\n",
    "    delta_hat_train=np.zeros((n_test,target_values.shape[0]))\n",
    "    \n",
    "    k=0\n",
    "    for y in target_values:\n",
    "        delta_hat_test[:,k]=delta(test_features,mu_hat[k],sigma_hat[k],pi_hat[k])\n",
    "        delta_hat_train[:,k]=delta(train_features,mu_hat[k],sigma_hat[k],pi_hat[k])\n",
    "        k+=1\n",
    "    predict_test=np.argmax(delta_hat_test,axis=1)\n",
    "    predict_train=np.argmax(delta_hat_train,axis=1)\n",
    "    \n",
    "    res={\"predict_test\": predict_test,\\\n",
    "        \"predict_train\": predict_train}\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7  3.   4.2  1.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 5.9  3.   5.1  1.8]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 6.1  2.9  4.7  1.4]]\n",
      "[1 0 2 2 0 1 1 1 2 1 1 2 2 2 2 1 2 1 2 1 1 2 0 0 0 1 2 2 2 0 0 0 0 2 0 0 2\n",
      " 1 2 0 1 0 0 0 2 0 2 1 0 1 2 2 1 0 2 2 0 1 0 1 1 2 0 1 1 1 2 0 2 1 0 1 0 0\n",
      " 1]\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]]\n"
     ]
    }
   ],
   "source": [
    "print(data_train)\n",
    "print(target_train)\n",
    "print(iris.data[test,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predict_test': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2,\n",
       "        2, 2, 2, 2, 2, 2], dtype=int64),\n",
       " 'predict_train': array([1, 0, 2, 2, 0, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0,\n",
       "        0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n",
       "        2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 2, 0, 2,\n",
       "        1, 0, 1, 0, 0, 1], dtype=int64)}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=MonNaiveBayes(data_train,target_train,iris.data[test,])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-4ff84e563ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(\"pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.7  3.   4.2  1.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 6.9  3.1  5.4  2.1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "np.argmax(x,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Comparer le r√©sultat au r√©sultat de la fonction de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function deepcopy in module copy:\n",
      "\n",
      "deepcopy(x, memo=None, _nil=[])\n",
      "    Deep copy operation on arbitrary Python objects.\n",
      "    \n",
      "    See the module's __doc__ string for more info.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-c63c4e5a3bc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0miris2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0miris2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mMonNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-94-cd31e11effa7>\u001b[0m in \u001b[0;36mMonNaiveBayes\u001b[1;34m(train_features, train_label)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMonNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtarget_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmu_hat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msigma_hat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_label' is not defined"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "help(copy.deepcopy)\n",
    "iris2 = copy.deepcopy(iris)\n",
    "\n",
    "iris2.data = iris2.data[3:30,]\n",
    "iris2.target = iris2.target[3:30,]\n",
    "MonNaiveBayes(iris, iris2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
